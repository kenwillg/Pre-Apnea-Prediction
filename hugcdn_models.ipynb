{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cd949c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow not available, will skip Neural Network\n",
      "================================================================================\n",
      "HuGCDN Pre-Apnea Model Comparison\n",
      "Neural Network (CNN) vs SVM vs Random Forest\n",
      "================================================================================\n",
      "\n",
      "Loading data with T=200, HORIZON=1...\n",
      "Loading 83 subjects with T=200...\n",
      "  Loaded: X=(33367, 200, 1), y=(33367,)\n",
      "\n",
      "Dataset Statistics:\n",
      "  Total samples: 33367\n",
      "  Apnea events: 7706 (23.1%)\n",
      "  Pre-apnea: 7706 (23.1%)\n",
      "\n",
      "Split: Train=23356, Val=5005, Test=5006\n",
      "\n",
      "Class weights: {0: 0.6501503173365994, 1: 2.164998146088246}\n",
      "\n",
      "\n",
      "================================================================================\n",
      "2. SUPPORT VECTOR MACHINE (SVM)\n",
      "================================================================================\n",
      "\n",
      "--- SVM (RBF kernel) ---\n",
      "\n",
      "============================================================\n",
      "SVM (rbf) Results\n",
      "============================================================\n",
      "Accuracy:    80.38%\n",
      "Precision:   55.88%\n",
      "Recall:      71.54%\n",
      "F1-Score:    62.75%\n",
      "Specificity: 83.04%\n",
      "AUC:         0.8464\n",
      "\n",
      "Confusion Matrix:\n",
      "  TN: 3197  FP:  653\n",
      "  FN:  329  TP:  827\n",
      "\n",
      "--- SVM (LINEAR kernel) ---\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "HuGCDN Model Comparison for Pre-Apnea Detection\n",
    "Compares: Neural Network (CNN), SVM, Random Forest\n",
    "\n",
    "Tests different window sizes (T) and prediction horizons\n",
    "to find optimal configuration for MAX30102 deployment\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             accuracy_score, precision_recall_fscore_support,\n",
    "                             roc_curve, auc)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# TensorFlow for Neural Network\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers, models\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "    TF_AVAILABLE = True\n",
    "except:\n",
    "    TF_AVAILABLE = False\n",
    "    print(\"TensorFlow not available, will skip Neural Network\")\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "BASE_DIR = Path(r\"D:\\School Stuff\\Pradita University\\SEM 5\\MLDL\\Pre-Apnea-Prediction\")\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "HUGCDN_DIR = DATA_DIR / \"HuGCDN2014-OXI\"\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "if TF_AVAILABLE:\n",
    "    tf.random.set_seed(RANDOM_STATE)\n",
    "\n",
    "# Test different configurations\n",
    "WINDOW_SIZES = [60, 120, 180, 200]  # seconds (1, 2, 3, 3.3 minutes)\n",
    "PREDICTION_HORIZONS = [1, 2, 3]      # minutes ahead to predict\n",
    "\n",
    "# Best config from testing (you'll update this)\n",
    "T_BEST = 200\n",
    "HORIZON_BEST = 1\n",
    "\n",
    "# =============================================================================\n",
    "# DATA LOADING FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def load_labels(path: Path) -> np.ndarray:\n",
    "    \"\"\"Load per-minute labels\"\"\"\n",
    "    d = loadmat(str(path))\n",
    "    if \"salida_man_1m\" in d:\n",
    "        raw = d[\"salida_man_1m\"]\n",
    "    elif \"salida_man\" in d:\n",
    "        raw = d[\"salida_man\"]\n",
    "    else:\n",
    "        keys = [k for k in d.keys() if not k.startswith(\"__\")]\n",
    "        raw = d[keys[0]]\n",
    "    return np.ravel(raw).astype(int)\n",
    "\n",
    "\n",
    "def extract_epoch_series(raw) -> list:\n",
    "    \"\"\"Convert MATLAB array to list of 1D arrays\"\"\"\n",
    "    arr = np.array(raw)\n",
    "    \n",
    "    if arr.dtype == object:\n",
    "        epochs = []\n",
    "        for x in arr.ravel():\n",
    "            x = np.array(x).astype(float).ravel()\n",
    "            if x.size > 0:\n",
    "                epochs.append(x)\n",
    "        return epochs\n",
    "    \n",
    "    arr = np.squeeze(arr)\n",
    "    if arr.ndim == 1:\n",
    "        return [arr.astype(float)]\n",
    "    else:\n",
    "        return [arr[i, :].astype(float).ravel() for i in range(arr.shape[0])]\n",
    "\n",
    "\n",
    "def load_sat_epochs(path: Path) -> list:\n",
    "    \"\"\"Load SpO2 epochs\"\"\"\n",
    "    d = loadmat(str(path))\n",
    "    for name in [\"sat\", \"Sat\", \"SaO2\", \"satO2\", \"SaO2_1m\"]:\n",
    "        if name in d:\n",
    "            raw = d[name]\n",
    "            break\n",
    "    else:\n",
    "        keys = [k for k in d.keys() if not k.startswith(\"__\")]\n",
    "        raw = d[keys[0]]\n",
    "    return extract_epoch_series(raw)\n",
    "\n",
    "\n",
    "def resize_epoch(x: np.ndarray, target_len: int) -> np.ndarray:\n",
    "    \"\"\"Linearly resample to fixed length\"\"\"\n",
    "    x = np.asarray(x, dtype=float).ravel()\n",
    "    if x.size == 0:\n",
    "        return np.zeros(target_len, dtype=float)\n",
    "    if x.size == target_len:\n",
    "        return x\n",
    "    old_idx = np.linspace(0.0, 1.0, num=x.size)\n",
    "    new_idx = np.linspace(0.0, 1.0, num=target_len)\n",
    "    return np.interp(new_idx, old_idx, x)\n",
    "\n",
    "\n",
    "def load_hugcdn_subject(subject_id: str, T: int = 200):\n",
    "    \"\"\"Load one subject with fixed-length epochs\"\"\"\n",
    "    label_path = HUGCDN_DIR / \"LABELS\" / f\"{subject_id}.mat\"\n",
    "    sat_path = HUGCDN_DIR / \"SAT\" / f\"{subject_id}.mat\"\n",
    "\n",
    "    labels = load_labels(label_path)\n",
    "    sat_ep = load_sat_epochs(sat_path)\n",
    "\n",
    "    n_epochs = min(len(labels), len(sat_ep))\n",
    "    if n_epochs == 0:\n",
    "        raise ValueError(f\"No usable epochs for {subject_id}\")\n",
    "\n",
    "    labels = labels[:n_epochs]\n",
    "    sat_ep = sat_ep[:n_epochs]\n",
    "\n",
    "    # Resample each epoch to length T\n",
    "    sat_resampled = np.stack([resize_epoch(e, T) for e in sat_ep], axis=0)\n",
    "\n",
    "    # Z-normalize per epoch\n",
    "    mu = sat_resampled.mean(axis=1, keepdims=True)\n",
    "    sigma = sat_resampled.std(axis=1, keepdims=True) + 1e-6\n",
    "    sat_z = (sat_resampled - mu) / sigma\n",
    "\n",
    "    # Reshape to (n_epochs, T, 1) for CNN\n",
    "    X = sat_z[:, :, np.newaxis]\n",
    "    y = labels.astype(int)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def load_all_hugcdn(T: int = 200):\n",
    "    \"\"\"Load all subjects\"\"\"\n",
    "    label_dir = HUGCDN_DIR / \"LABELS\"\n",
    "    subject_ids = sorted([f.stem for f in label_dir.glob(\"*.mat\")])\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    subj_idx = []\n",
    "\n",
    "    print(f\"Loading {len(subject_ids)} subjects with T={T}...\")\n",
    "    for sid in subject_ids:\n",
    "        try:\n",
    "            X_s, y_s = load_hugcdn_subject(sid, T=T)\n",
    "            X_list.append(X_s)\n",
    "            y_list.append(y_s)\n",
    "            subj_idx.extend([sid] * len(y_s))\n",
    "        except Exception as e:\n",
    "            print(f\"  Skipping {sid}: {e}\")\n",
    "\n",
    "    X = np.concatenate(X_list, axis=0)\n",
    "    y = np.concatenate(y_list, axis=0)\n",
    "    subject_idx = np.array(subj_idx)\n",
    "\n",
    "    print(f\"  Loaded: X={X.shape}, y={y.shape}\")\n",
    "    return X, y, subject_idx\n",
    "\n",
    "\n",
    "def make_pre_apnea_labels(y, subject_idx, horizon=1):\n",
    "    \"\"\"Create pre-apnea labels (1 if apnea in next 'horizon' minutes)\"\"\"\n",
    "    y = np.asarray(y).astype(int)\n",
    "    pre_y = np.zeros_like(y)\n",
    "\n",
    "    unique_subj = np.unique(subject_idx)\n",
    "    for sid in unique_subj:\n",
    "        mask = (subject_idx == sid)\n",
    "        idxs = np.where(mask)[0]\n",
    "        labels_sub = y[mask]\n",
    "\n",
    "        for j, global_idx in enumerate(idxs):\n",
    "            end_j = min(len(labels_sub), j + 1 + horizon)\n",
    "            if np.any(labels_sub[j + 1:end_j] == 1):\n",
    "                pre_y[global_idx] = 1\n",
    "\n",
    "    return pre_y\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL BUILDERS\n",
    "# =============================================================================\n",
    "\n",
    "def build_cnn_model(input_shape, model_size='small'):\n",
    "    \"\"\"Build CNN for TinyML deployment\"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    if model_size == 'tiny':\n",
    "        # Minimal model for tight memory\n",
    "        x = layers.Conv1D(8, kernel_size=5, activation=\"relu\", padding=\"same\")(inputs)\n",
    "        x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "        x = layers.Conv1D(16, kernel_size=5, activation=\"relu\", padding=\"same\")(x)\n",
    "        x = layers.GlobalAveragePooling1D()(x)\n",
    "        x = layers.Dense(16, activation=\"relu\")(x)\n",
    "        \n",
    "    elif model_size == 'small':\n",
    "        # Balanced model (your original)\n",
    "        x = layers.Conv1D(16, kernel_size=5, activation=\"relu\", padding=\"same\")(inputs)\n",
    "        x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "        x = layers.Conv1D(32, kernel_size=5, activation=\"relu\", padding=\"same\")(x)\n",
    "        x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "        x = layers.Conv1D(64, kernel_size=3, activation=\"relu\", padding=\"same\")(x)\n",
    "        x = layers.GlobalAveragePooling1D()(x)\n",
    "        x = layers.Dense(32, activation=\"relu\")(x)\n",
    "        \n",
    "    else:  # 'medium'\n",
    "        # Larger model for best accuracy\n",
    "        x = layers.Conv1D(32, kernel_size=5, activation=\"relu\", padding=\"same\")(inputs)\n",
    "        x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "        x = layers.Conv1D(64, kernel_size=5, activation=\"relu\", padding=\"same\")(x)\n",
    "        x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "        x = layers.Conv1D(128, kernel_size=3, activation=\"relu\", padding=\"same\")(x)\n",
    "        x = layers.GlobalAveragePooling1D()(x)\n",
    "        x = layers.Dense(64, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        x = layers.Dense(32, activation=\"relu\")(x)\n",
    "\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EVALUATION FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def evaluate_model(y_true, y_pred, y_pred_proba=None, model_name=\"Model\"):\n",
    "    \"\"\"Comprehensive evaluation metrics\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Basic metrics\n",
    "    results['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)\n",
    "    results['precision'] = prec\n",
    "    results['recall'] = rec\n",
    "    results['f1'] = f1\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    results['tn'] = tn\n",
    "    results['fp'] = fp\n",
    "    results['fn'] = fn\n",
    "    results['tp'] = tp\n",
    "    results['specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    # ROC AUC if probabilities available\n",
    "    if y_pred_proba is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "        results['auc'] = auc(fpr, tpr)\n",
    "    else:\n",
    "        results['auc'] = None\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{model_name} Results\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Accuracy:    {results['accuracy']*100:.2f}%\")\n",
    "    print(f\"Precision:   {results['precision']*100:.2f}%\")\n",
    "    print(f\"Recall:      {results['recall']*100:.2f}%\")\n",
    "    print(f\"F1-Score:    {results['f1']*100:.2f}%\")\n",
    "    print(f\"Specificity: {results['specificity']*100:.2f}%\")\n",
    "    if results['auc']:\n",
    "        print(f\"AUC:         {results['auc']:.4f}\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"  TN: {tn:4d}  FP: {fp:4d}\")\n",
    "    print(f\"  FN: {fn:4d}  TP: {tp:4d}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN COMPARISON\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*80)\n",
    "    print(\"HuGCDN Pre-Apnea Model Comparison\")\n",
    "    print(\"Neural Network (CNN) vs SVM vs Random Forest\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    # Load data with best configuration\n",
    "    print(f\"Loading data with T={T_BEST}, HORIZON={HORIZON_BEST}...\")\n",
    "    X, y_apnea, subject_idx = load_all_hugcdn(T=T_BEST)\n",
    "    \n",
    "    # Create pre-apnea labels\n",
    "    y_pre = make_pre_apnea_labels(y_apnea, subject_idx, horizon=HORIZON_BEST)\n",
    "    \n",
    "    print(f\"\\nDataset Statistics:\")\n",
    "    print(f\"  Total samples: {len(y_pre)}\")\n",
    "    print(f\"  Apnea events: {np.sum(y_apnea)} ({np.sum(y_apnea)/len(y_apnea)*100:.1f}%)\")\n",
    "    print(f\"  Pre-apnea: {np.sum(y_pre)} ({np.sum(y_pre)/len(y_pre)*100:.1f}%)\")\n",
    "    print()\n",
    "    \n",
    "    # Shuffle and split\n",
    "    X_shuf, y_shuf = shuffle(X, y_pre, random_state=RANDOM_STATE)\n",
    "    \n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X_shuf, y_shuf, test_size=0.3, random_state=RANDOM_STATE, stratify=y_shuf\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=RANDOM_STATE, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    print(f\"Split: Train={len(X_train)}, Val={len(X_val)}, Test={len(X_test)}\")\n",
    "    print()\n",
    "    \n",
    "    # Calculate class weights\n",
    "    binc = np.bincount(y_train)\n",
    "    if len(binc) == 1:\n",
    "        class_weight = {0: 1.0}\n",
    "    else:\n",
    "        total = float(binc.sum())\n",
    "        class_weight = {\n",
    "            0: total / (2.0 * binc[0]),\n",
    "            1: total / (2.0 * binc[1]),\n",
    "        }\n",
    "    print(f\"Class weights: {class_weight}\")\n",
    "    print()\n",
    "    \n",
    "    # Storage for results\n",
    "    all_results = []\n",
    "    \n",
    "    # =========================================================================\n",
    "    # MODEL 1: NEURAL NETWORK (CNN)\n",
    "    # =========================================================================\n",
    "    if TF_AVAILABLE:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"1. NEURAL NETWORK (CNN) - Multiple Sizes\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for model_size in ['tiny', 'small', 'medium']:\n",
    "            print(f\"\\n--- CNN ({model_size.upper()}) ---\")\n",
    "            \n",
    "            model = build_cnn_model(input_shape=(T_BEST, 1), model_size=model_size)\n",
    "            \n",
    "            # Count parameters\n",
    "            total_params = model.count_params()\n",
    "            print(f\"Total parameters: {total_params:,}\")\n",
    "            \n",
    "            # Estimate model size\n",
    "            model_size_kb = (total_params * 4) / 1024  # 4 bytes per float32\n",
    "            print(f\"Estimated model size: {model_size_kb:.1f} KB (float32)\")\n",
    "            print(f\"Quantized (int8): ~{model_size_kb/4:.1f} KB\")\n",
    "            \n",
    "            # Train\n",
    "            early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "            \n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                validation_data=(X_val, y_val),\n",
    "                epochs=50,\n",
    "                batch_size=64,\n",
    "                class_weight=class_weight,\n",
    "                callbacks=[early_stop],\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            # Evaluate\n",
    "            y_pred_proba = model.predict(X_test, verbose=0).ravel()\n",
    "            y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "            \n",
    "            results = evaluate_model(y_test, y_pred, y_pred_proba, \n",
    "                                    model_name=f\"CNN ({model_size})\")\n",
    "            results['model'] = f'CNN_{model_size}'\n",
    "            results['params'] = total_params\n",
    "            results['size_kb'] = model_size_kb\n",
    "            all_results.append(results)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # MODEL 2: SVM\n",
    "    # =========================================================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"2. SUPPORT VECTOR MACHINE (SVM)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Flatten X for SVM (needs 2D input)\n",
    "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "    \n",
    "    # Standardize\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_flat)\n",
    "    X_test_scaled = scaler.transform(X_test_flat)\n",
    "    \n",
    "    # Try different kernels\n",
    "    for kernel in ['rbf', 'linear']:\n",
    "        print(f\"\\n--- SVM ({kernel.upper()} kernel) ---\")\n",
    "        \n",
    "        svm_model = SVC(\n",
    "            kernel=kernel,\n",
    "            C=1.0,\n",
    "            gamma='scale' if kernel == 'rbf' else 'auto',\n",
    "            random_state=RANDOM_STATE,\n",
    "            probability=True,\n",
    "            class_weight='balanced'\n",
    "        )\n",
    "        \n",
    "        svm_model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        y_pred = svm_model.predict(X_test_scaled)\n",
    "        y_pred_proba = svm_model.predict_proba(X_test_scaled)[:, 1]\n",
    "        \n",
    "        results = evaluate_model(y_test, y_pred, y_pred_proba, \n",
    "                                model_name=f\"SVM ({kernel})\")\n",
    "        results['model'] = f'SVM_{kernel}'\n",
    "        results['params'] = len(svm_model.support_vectors_)\n",
    "        results['size_kb'] = None  # Hard to estimate\n",
    "        all_results.append(results)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # MODEL 3: RANDOM FOREST\n",
    "    # =========================================================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"3. RANDOM FOREST\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Try different sizes\n",
    "    for n_trees in [10, 50, 100]:\n",
    "        print(f\"\\n--- Random Forest ({n_trees} trees) ---\")\n",
    "        \n",
    "        rf_model = RandomForestClassifier(\n",
    "            n_estimators=n_trees,\n",
    "            max_depth=20,\n",
    "            min_samples_split=10,\n",
    "            min_samples_leaf=5,\n",
    "            random_state=RANDOM_STATE,\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        rf_model.fit(X_train_flat, y_train)\n",
    "        \n",
    "        y_pred = rf_model.predict(X_test_flat)\n",
    "        y_pred_proba = rf_model.predict_proba(X_test_flat)[:, 1]\n",
    "        \n",
    "        results = evaluate_model(y_test, y_pred, y_pred_proba, \n",
    "                                model_name=f\"Random Forest ({n_trees} trees)\")\n",
    "        results['model'] = f'RF_{n_trees}'\n",
    "        results['params'] = None  # Complex to estimate\n",
    "        results['size_kb'] = None\n",
    "        all_results.append(results)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # COMPARISON VISUALIZATION\n",
    "    # =========================================================================\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    print(\"\\n\\n\" + \"=\"*80)\n",
    "    print(\"COMPREHENSIVE COMPARISON\")\n",
    "    print(\"=\"*80)\n",
    "    print(results_df[['model', 'accuracy', 'precision', 'recall', 'f1', 'auc']].to_string(index=False))\n",
    "    \n",
    "    # Plot comparison\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Accuracy comparison\n",
    "    ax1 = axes[0, 0]\n",
    "    models = results_df['model']\n",
    "    accuracies = results_df['accuracy'] * 100\n",
    "    \n",
    "    colors = ['steelblue' if 'CNN' in m else 'forestgreen' if 'SVM' in m else 'coral' \n",
    "              for m in models]\n",
    "    \n",
    "    bars = ax1.barh(range(len(models)), accuracies, color=colors, edgecolor='black', linewidth=1.5)\n",
    "    ax1.set_yticks(range(len(models)))\n",
    "    ax1.set_yticklabels(models, fontsize=9)\n",
    "    ax1.set_xlabel('Accuracy (%)', fontsize=11, fontweight='bold')\n",
    "    ax1.set_title('Model Accuracy Comparison', fontsize=12, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    for i, (bar, acc) in enumerate(zip(bars, accuracies)):\n",
    "        ax1.text(acc + 1, i, f'{acc:.1f}%', va='center', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    # 2. F1-Score comparison\n",
    "    ax2 = axes[0, 1]\n",
    "    f1_scores = results_df['f1'] * 100\n",
    "    \n",
    "    bars = ax2.barh(range(len(models)), f1_scores, color=colors, edgecolor='black', linewidth=1.5)\n",
    "    ax2.set_yticks(range(len(models)))\n",
    "    ax2.set_yticklabels(models, fontsize=9)\n",
    "    ax2.set_xlabel('F1-Score (%)', fontsize=11, fontweight='bold')\n",
    "    ax2.set_title('F1-Score Comparison', fontsize=12, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    for i, (bar, f1) in enumerate(zip(bars, f1_scores)):\n",
    "        ax2.text(f1 + 1, i, f'{f1:.1f}%', va='center', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    # 3. Precision vs Recall\n",
    "    ax3 = axes[1, 0]\n",
    "    for idx, row in results_df.iterrows():\n",
    "        color = 'steelblue' if 'CNN' in row['model'] else 'forestgreen' if 'SVM' in row['model'] else 'coral'\n",
    "        ax3.scatter(row['recall']*100, row['precision']*100, s=200, \n",
    "                   c=color, edgecolors='black', linewidths=2, alpha=0.7)\n",
    "        ax3.annotate(row['model'], (row['recall']*100, row['precision']*100), \n",
    "                    fontsize=8, ha='right', va='bottom')\n",
    "    \n",
    "    ax3.set_xlabel('Recall (%)', fontsize=11, fontweight='bold')\n",
    "    ax3.set_ylabel('Precision (%)', fontsize=11, fontweight='bold')\n",
    "    ax3.set_title('Precision vs Recall', fontsize=12, fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.plot([0, 100], [0, 100], 'k--', alpha=0.3, label='Perfect balance')\n",
    "    ax3.legend()\n",
    "    \n",
    "    # 4. Confusion matrix for best model\n",
    "    ax4 = axes[1, 1]\n",
    "    best_idx = results_df['f1'].idxmax()\n",
    "    best = results_df.iloc[best_idx]\n",
    "    \n",
    "    cm = np.array([[best['tn'], best['fp']], [best['fn'], best['tp']]])\n",
    "    \n",
    "    im = ax4.imshow(cm, cmap='Blues', alpha=0.8)\n",
    "    ax4.set_xticks([0, 1])\n",
    "    ax4.set_yticks([0, 1])\n",
    "    ax4.set_xticklabels(['Normal', 'Pre-Apnea'], fontsize=10)\n",
    "    ax4.set_yticklabels(['Normal', 'Pre-Apnea'], fontsize=10)\n",
    "    ax4.set_xlabel('Predicted', fontsize=11, fontweight='bold')\n",
    "    ax4.set_ylabel('Actual', fontsize=11, fontweight='bold')\n",
    "    ax4.set_title(f'Best Model: {best[\"model\"]}\\nF1={best[\"f1\"]*100:.1f}%', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    \n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax4.text(j, i, int(cm[i, j]), ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > cm.max()/2 else \"black\",\n",
    "                    fontsize=16, fontweight='bold')\n",
    "    \n",
    "    plt.colorbar(im, ax=ax4)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # =========================================================================\n",
    "    # FINAL RECOMMENDATIONS\n",
    "    # =========================================================================\n",
    "    print(\"\\n\\n\" + \"=\"*80)\n",
    "    print(\"ðŸŽ¯ RECOMMENDATIONS FOR ESP32 DEPLOYMENT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    best = results_df.loc[results_df['f1'].idxmax()]\n",
    "    \n",
    "    print(f\"\\nðŸ† BEST OVERALL MODEL: {best['model']}\")\n",
    "    print(f\"   Accuracy:  {best['accuracy']*100:.2f}%\")\n",
    "    print(f\"   F1-Score:  {best['f1']*100:.2f}%\")\n",
    "    print(f\"   Recall:    {best['recall']*100:.2f}% (detection rate)\")\n",
    "    print(f,\"   Precision: {best['precision']*100:.2f}% (false alarm rate)\")\n",
    "    if best['auc']:\n",
    "        print(f\"   AUC:       {best['auc']:.4f}\")\n",
    "    \n",
    "    # Best per category\n",
    "    cnn_models = results_df[results_df['model'].str.contains('CNN')]\n",
    "    if len(cnn_models) > 0:\n",
    "        best_cnn = cnn_models.loc[cnn_models['f1'].idxmax()]\n",
    "        print(f\"\\nðŸ“± BEST FOR ESP32 (CNN): {best_cnn['model']}\")\n",
    "        print(f\"   F1-Score: {best_cnn['f1']*100:.2f}%\")\n",
    "        print(f\"   Model size: {best_cnn['size_kb']:.1f} KB (float32), ~{best_cnn['size_kb']/4:.1f} KB (int8)\")\n",
    "        print(f\"   Parameters: {best_cnn['params']:,}\")\n",
    "        \n",
    "        if best_cnn['size_kb'] < 100:\n",
    "            print(f\"   âœ… FITS EASILY on ESP32 (520KB SRAM available)\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸ May be tight on ESP32, consider quantization\")\n",
    "    \n",
    "    svm_models = results_df[results_df['model'].str.contains('SVM')]\n",
    "    if len(svm_models) > 0:\n",
    "        best_svm = svm_models.loc[svm_models['f1'].idxmax()]\n",
    "        print(f\"\\nðŸ”µ BEST SVM: {best_svm['model']}\")\n",
    "        print(f\"   F1-Score: {best_svm['f1']*100:.2f}%\")\n",
    "        print(f\"   Note: SVM harder to deploy on ESP32 (needs CMSIS-NN or manual implementation)\")\n",
    "    \n",
    "    rf_models = results_df[results_df['model'].str.contains('RF')]\n",
    "    if len(rf_models) > 0:\n",
    "        best_rf = rf_models.loc[rf_models['f1'].idxmax()]\n",
    "        print(f\"\\nðŸŒ² BEST RANDOM FOREST: {best_rf['model']}\")\n",
    "        print(f\"   F1-Score: {best_rf['f1']*100:.2f}%\")\n",
    "        print(f\"   Note: RF can be deployed using EloquentTinyML or manual implementation\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"NEXT STEPS:\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\"\"\n",
    "1. If CNN performs best:\n",
    "   â†’ Use TensorFlow Lite for Microcontrollers\n",
    "   â†’ Quantize to INT8 for smaller size\n",
    "   â†’ Already have ESP32 code template!\n",
    "   \n",
    "2. If SVM performs best:\n",
    "   â†’ Consider emlearn library for ESP32\n",
    "   â†’ Or implement decision function manually\n",
    "   \n",
    "3. If Random Forest performs best:\n",
    "   â†’ Use EloquentTinyML library\n",
    "   â†’ Or export as C code\n",
    "   \n",
    "4. Model optimization:\n",
    "   â†’ Try different window sizes (T)\n",
    "   â†’ Adjust prediction horizon\n",
    "   â†’ Feature engineering (add desaturation features)\n",
    "    \"\"\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Save results\n",
    "    results_df.to_csv(BASE_DIR / \"model_comparison_results.csv\", index=False)\n",
    "    print(f\"\\nâœ“ Results saved to: {BASE_DIR / 'model_comparison_results.csv'}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyml-apnea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
